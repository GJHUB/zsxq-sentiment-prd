"""çŸ¥è¯†æ˜Ÿçƒè‚¡ç¥¨èˆ†æƒ…åˆ†æå™¨ - ä¸»å…¥å£

ç”¨æ³•ï¼š
  python main.py fetch --start-date 2026-02-14          # åªçˆ¬å–æ•°æ®
  python main.py analyze --data data/topics_xxx.json     # åªåˆ†ææ•°æ®
  python main.py run --start-date 2026-02-14             # çˆ¬å–+åˆ†æä¸€æ¡é¾™
"""

import argparse
import asyncio
import json
import logging
import sys
from datetime import datetime
from pathlib import Path

from src.auth import AuthManager
from src.config import get_config
from src.crawler import ZsxqCrawler
from src.analyzer import SentimentAnalyzer
from src.report import ReportGenerator
from src.notify import WeChatNotifier


def setup_logging():
    """é…ç½®æ—¥å¿—"""
    log_dir = get_config("log_dir", "logs")
    Path(log_dir).mkdir(parents=True, exist_ok=True)

    today = datetime.now().strftime("%Y-%m-%d")
    log_file = Path(log_dir) / f"{today}.log"

    logging.basicConfig(
        level=getattr(logging, get_config("log_level", "INFO")),
        format="%(asctime)s [%(levelname)s] %(name)s: %(message)s",
        handlers=[
            logging.FileHandler(log_file, encoding="utf-8"),
            logging.StreamHandler(sys.stdout),
        ],
    )


async def do_fetch(args) -> str:
    """çˆ¬å–å¸–å­å’Œè¯„è®ºï¼Œä¿å­˜åˆ°JSON"""
    logger = logging.getLogger(__name__)
    notifier = WeChatNotifier()
    auth = AuthManager(
        cookie_path=get_config("cookie_path"),
        notify_func=notifier.send_image,
    )

    # è·å–Cookie
    cookie = await auth.get_cookie()
    if not cookie:
        notifier.send_alert("Cookieè·å–å¤±è´¥ï¼Œè¯·æ£€æŸ¥")
        logger.error("Cookieè·å–å¤±è´¥ï¼Œé€€å‡º")
        return ""

    # çˆ¬å–
    crawler = ZsxqCrawler(group_id=get_config("group_id"), cookie=cookie)

    end_date = args.end_date or datetime.now().strftime("%Y-%m-%d")
    if args.start_date:
        topics = await crawler.fetch_date_range(args.start_date, end_date)
        date_label = f"{args.start_date}_to_{end_date}"
    else:
        topics = await crawler.fetch_all_today()
        date_label = datetime.now().strftime("%Y-%m-%d")

    if not topics:
        notifier.send_text("ğŸ“­ æŒ‡å®šæ—¥æœŸèŒƒå›´å†…æš‚æ— æ–°å†…å®¹")
        logger.info("æš‚æ— æ–°å†…å®¹")
        return ""

    # ä¿å­˜åˆ°JSON
    data_dir = Path("data")
    data_dir.mkdir(parents=True, exist_ok=True)
    output_path = str(data_dir / f"topics_{date_label}.json")

    with open(output_path, "w", encoding="utf-8") as f:
        json.dump(topics, f, ensure_ascii=False, indent=2)

    logger.info("æ•°æ®å·²ä¿å­˜: %sï¼ˆ%d æ¡å¸–å­ï¼‰", output_path, len(topics))
    notifier.send_text(f"ğŸ“¥ æ•°æ®çˆ¬å–å®Œæˆï¼š{len(topics)} æ¡å¸–å­\nğŸ“„ æ–‡ä»¶: {output_path}")
    return output_path


async def do_analyze(args) -> str:
    """è¯»å–JSONæ•°æ®ï¼Œè°ƒç”¨å¤§æ¨¡å‹åˆ†æï¼Œç”ŸæˆæŠ¥å‘Š"""
    logger = logging.getLogger(__name__)
    notifier = WeChatNotifier()

    # åŠ è½½æ•°æ®
    data_path = args.data
    if not Path(data_path).exists():
        logger.error("æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: %s", data_path)
        return ""

    with open(data_path, "r", encoding="utf-8") as f:
        topics = json.load(f)

    logger.info("åŠ è½½äº† %d æ¡å¸–å­", len(topics))

    # AIåˆ†æ
    analyzer = SentimentAnalyzer(
        openai_api_key=get_config("openai_api_key"),
        anthropic_api_key=get_config("anthropic_api_key"),
    )
    analysis = await analyzer.analyze_topics(topics)

    if analysis.empty:
        notifier.send_text("ğŸ“­ å†…å®¹ä¸­æœªå‘ç°å¯åˆ†æçš„è´¢ç»ä¿¡æ¯")
        return ""

    # ä»æ–‡ä»¶åæå–æ—¥æœŸæ ‡ç­¾
    stem = Path(data_path).stem  # topics_2026-02-14_to_2026-02-19
    date_label = stem.replace("topics_", "") or datetime.now().strftime("%Y-%m-%d")

    # ç”ŸæˆæŠ¥å‘Š
    reporter = ReportGenerator()
    report_path = reporter.generate(analysis, topics, date=date_label)

    # ç»Ÿè®¡
    financial_count = len(analysis[analysis["is_financial"] == True]) if not analysis.empty else 0

    summary = (
        f"ğŸ“Š èˆ†æƒ…åˆ†æå®Œæˆ\n\n"
        f"ğŸ“ å¸–å­æ•°: {len(topics)}\n"
        f"ğŸ’° è´¢ç»ç›¸å…³: {financial_count} æ¡\n"
        f"ğŸ“„ æŠ¥å‘Š: {report_path}"
    )
    notifier.send_text(summary)
    notifier.send_file(report_path, "èˆ†æƒ…åˆ†ææŠ¥å‘Š")

    logger.info("=== åˆ†æå®Œæˆ ===")
    return report_path


async def do_run(args):
    """çˆ¬å–+åˆ†æä¸€æ¡é¾™"""
    logger = logging.getLogger(__name__)
    logger.info("=== çŸ¥è¯†æ˜Ÿçƒèˆ†æƒ…åˆ†æå¼€å§‹ ===")

    try:
        # 1. çˆ¬å–
        data_path = await do_fetch(args)
        if not data_path:
            return

        # 2. åˆ†æ
        args.data = data_path
        await do_analyze(args)

        logger.info("=== å…¨éƒ¨å®Œæˆ ===")
    except Exception as e:
        logger.exception("è¿è¡Œå¼‚å¸¸")
        WeChatNotifier().send_alert(f"è¿è¡Œå¼‚å¸¸: {str(e)}")
        raise


def main():
    parser = argparse.ArgumentParser(description="çŸ¥è¯†æ˜Ÿçƒè‚¡ç¥¨èˆ†æƒ…åˆ†æå™¨")
    subparsers = parser.add_subparsers(dest="command", help="å­å‘½ä»¤")

    # fetch
    fetch_parser = subparsers.add_parser("fetch", help="çˆ¬å–å¸–å­å’Œè¯„è®º")
    fetch_parser.add_argument("--start-date", type=str, help="èµ·å§‹æ—¥æœŸ YYYY-MM-DD")
    fetch_parser.add_argument("--end-date", type=str, help="ç»“æŸæ—¥æœŸ YYYY-MM-DD")

    # analyze
    analyze_parser = subparsers.add_parser("analyze", help="åˆ†æå·²çˆ¬å–çš„æ•°æ®")
    analyze_parser.add_argument("--data", type=str, required=True, help="æ•°æ®JSONæ–‡ä»¶è·¯å¾„")

    # run (fetch + analyze)
    run_parser = subparsers.add_parser("run", help="çˆ¬å–+åˆ†æä¸€æ¡é¾™")
    run_parser.add_argument("--start-date", type=str, help="èµ·å§‹æ—¥æœŸ YYYY-MM-DD")
    run_parser.add_argument("--end-date", type=str, help="ç»“æŸæ—¥æœŸ YYYY-MM-DD")

    args = parser.parse_args()

    setup_logging()

    if args.command == "fetch":
        asyncio.run(do_fetch(args))
    elif args.command == "analyze":
        asyncio.run(do_analyze(args))
    elif args.command == "run":
        asyncio.run(do_run(args))
    else:
        # å…¼å®¹æ—§ç”¨æ³•ï¼šæ— å­å‘½ä»¤æ—¶é»˜è®¤ run
        parser.print_help()


if __name__ == "__main__":
    main()
